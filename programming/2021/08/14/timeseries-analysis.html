<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Timeseries Analysis in Python</title>
  <meta name="description" content="This post is about statistical models for timeseries analysis in Python. We will cover the ARIMA model to a certain depth.">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="https://alexandrugris.github.io/programming/2021/08/14/timeseries-analysis.html">
  <link rel="alternate" type="application/rss+xml" title="From The Trenches - The Code" href="/feed.xml">
  
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">

    <div class="site-nav"><a class="site-title" href="/">From The Trenches - The Code</a> </div>

    <nav class="site-nav">
      <span class="menu-icon">        
      </span>

      <div class="trigger">

        <a class="page-link" href="https://alexandrugris.github.io">Home</a>

        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
          <a class="page-link" href="/sm/">Social Media</a>
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Timeseries Analysis in Python</h1>
    <p class="post-meta"><time datetime="2021-08-14T09:15:16+02:00" itemprop="datePublished">Aug 14, 2021</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>This post is about statistical models for timeseries analysis in Python. We will cover the ARIMA model to a certain depth.</p>

<h3 id="linear-regression-and-timeseries">Linear Regression and Timeseries</h3>

<p>Using a linear regression with time series is problematic. Linear regression  assumes you have independently and identically distributed data. In time series data, points near in time tend to be strongly correlated with one another. In fact, when there aren’t temporal correlations, time series data is hardly useful for traditional time series tasks,
such as predicting the future or understanding temporal dynamics. Linear regression can be used with timeseries when linear regression assumptions hold. Such a case is when the predicted variable is fully dependent on its predictors, for instance when the timeseries component is entirely embedded in one of the features and the errors preserve the normality assumption with no autocorrelation.</p>

<h3 id="the-statistics-of-time-series">The Statistics Of Time Series</h3>

<p>An excellent introduction on time series can be found <a href="https://www.youtube.com/playlist?list=PLvcbYUQ5t0UHOLnBzl46_Q6QKtFgfMGc3">here</a>.</p>

<p>Timeseries bring several concepts of interest</p>

<ul>
  <li>Stationarity: constant statistical properties of the timeseries (mean, variance, no seasonality)</li>
  <li>Self-correlation: correlation between subsequent values of a timeseries</li>
  <li>Seasonality: time-based patterns tha repeat at set intervals</li>
  <li>Spurious correlations: the propensity of timeseries to correlate with other unrelated timeseries especially when seasonality or trends are present.</li>
</ul>

<p>A log transformation or a square root transformation are two usually good options for making a timeseries stationary,particularly in the case of changing variance over time.</p>

<p>Most of the timeseries have a trend, that is the mean is not constant - <a href="https://en.wikipedia.org/wiki/Trend-stationary_process">trend-stationarity</a> and <a href="https://en.wikipedia.org/wiki/Unit_root">difference-stationarity</a>. Removing a trend is most commonly done by differencing. Sometimes a series must be differenced more than once. However, if you find yourself differencing too much (more than two or three times) it is unlikely that you can fix your stationarity problem with differencing.</p>

<p>If <code class="highlighter-rouge">v(t_i+1) - v(t_i)</code> is random and stationary, then the process generating the series is a random walk, else a more refined model is required.</p>

<p>The test that is mainly used for testing stationarity is called the <a href="https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test">Augmented Dickey Fuller Test</a>. It removes the autocorrelation and tests for equal mean and equal variance throughout the series. The null hypothesis is the non-stationarity.</p>

<p>The Dickey Fuller test assumes that the time series is an AR1 process (auto-regressive one), that is, it can be written as <code class="highlighter-rouge">y(t) = phi * y(t-1) + constant + error</code>. The DF test’s null hypothesis is <code class="highlighter-rouge">phi &gt;= 1</code>. The alternate hypothesis is that <code class="highlighter-rouge">phi &lt; 1</code>.  This <code class="highlighter-rouge">phi == 1</code> is called a unit root. A good explanation of unit roots can be found <a href="https://www.youtube.com/watch?v=ugOvehrTRRw">here</a>.</p>

<p>ADF extends the test to ARn series and this null hypothesis is that <code class="highlighter-rouge">sum(phi_i)&gt;=1</code>. The difference between the basic DF test and the ADF test is that the latter makes is to account for more lags. The test of whether a series is stationary is a test of whether a series is integrated. An integrated series of order <code class="highlighter-rouge">n</code> is a series that must be differenced <code class="highlighter-rouge">n</code> times to become stationary.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">statsmodels.tsa.stattools</span> <span class="kn">import</span> <span class="n">adfuller</span>

<span class="k">def</span> <span class="nf">gen_ts</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">coefs</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">error</span><span class="p">):</span>
  <span class="k">assert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">start</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">coefs</span><span class="p">))</span>
  <span class="k">assert</span><span class="p">(</span><span class="n">count</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">start</span><span class="p">))</span>

  <span class="n">lst</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">count</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">start</span><span class="p">))</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">start</span><span class="p">),</span> <span class="n">count</span><span class="p">):</span>
    <span class="n">lst</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="n">error</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">start</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
      <span class="n">lst</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">coefs</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">lst</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="n">j</span><span class="p">]</span>

  <span class="k">return</span> <span class="n">lst</span>

<span class="n">v</span> <span class="o">=</span> <span class="n">gen_ts</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="mi">100</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span> <span class="c"># sum of coefficients &lt; 1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

<span class="c"># automatically test for the best lag to use</span>
<span class="c"># AIC comes from https://en.wikipedia.org/wiki/Akaike_information_criterion</span>
<span class="n">p_value</span> <span class="o">=</span> <span class="n">adfuller</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">autolag</span><span class="o">=</span><span class="s">'AIC'</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">p_value</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://alexandrugris.github.io/assets/tsa_adf.jpg" alt="ADF" /></p>

<p>For detecting auto correlation, we introduce two measures:</p>
<ul>
  <li>The <em>ACF</em> - the autocorrelation between the value at <code class="highlighter-rouge">t</code> and <code class="highlighter-rouge">t-n</code>, <em>including</em> the intermediary values, <code class="highlighter-rouge">(t-1 .. t-n-1)</code>. E.g. the effect of prices 2 months ago vs the prices today, including the effect of the prices 2 months ago on the prices 1 month ago and the prices from 1 month ago on today’s prices.</li>
  <li>The <em>PACF</em> - the autocorrelation between the value at <code class="highlighter-rouge">t</code> and <code class="highlighter-rouge">t-n</code> <em>excluding</em> the intermediary values.</li>
</ul>

<p>The ACF is the Pearson correlation between the values <code class="highlighter-rouge">ti</code> and the lagged <code class="highlighter-rouge">ti-k</code> values. For the PACF we do a regression on the values of the timeseries at time <code class="highlighter-rouge">ti</code> on the <code class="highlighter-rouge">ti-k</code> of the form <code class="highlighter-rouge">ti=phi_1*ti_-1 + phi_2*ti_-2 + ... + phi_k*ti_-k + error_term</code> - autoregressive lag <code class="highlighter-rouge">k</code>. <code class="highlighter-rouge">phi_k</code> is our PACF(k).</p>

<p>To plot these a real dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">lynx_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"/content/drive/MyDrive/Datasets/LYNXdata.csv"</span><span class="p">,</span> 
    <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
    <span class="n">header</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
    <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s">'year'</span><span class="p">,</span> <span class="s">'trappings'</span><span class="p">])</span>
</code></pre></div></div>

<p>And then transform it to time-annotated series:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lynx_ts</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
    <span class="n">lynx_df</span><span class="p">[</span><span class="s">"trappings"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> 
    <span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="s">'31/12/1821'</span><span class="p">,</span> 
    <span class="n">periods</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">lynx_df</span><span class="p">),</span> 
    <span class="n">freq</span><span class="o">=</span><span class="s">'A-DEC'</span><span class="p">))</span>

<span class="n">lynx_ts</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="https://alexandrugris.github.io/assets/tsa_lynx.jpg" alt="Lynx TS" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">statsmodels.graphics.tsaplots</span> <span class="kn">import</span> <span class="n">plot_acf</span><span class="p">,</span> <span class="n">plot_pacf</span>
<span class="n">plot_acf</span><span class="p">(</span><span class="n">lynx_ts</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plot_pacf</span><span class="p">(</span><span class="n">lynx_ts</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://alexandrugris.github.io/assets/tsa_acf.jpg" alt="ACF" /></p>

<p><img src="https://alexandrugris.github.io/assets/tsa_pacf.jpg" alt="PACF" /></p>

<p>We see in these charts that autocorrelation decreases as we look backwards in the series. This means that we are likely dealing with an auto-regressive process. If we are to build an auto-regressive model for this series we’ll probably consider the coefficients for the 1, 2, 4 and 6 lags. The blue bands are the error margin; everything within the bands are not statistically significant. The coefficient with index 0 is always 1, as it is the correlation of the timeseries with itself.</p>

<p>A series can be stationary, that is the mean is 0 and the variance constant with time, but with no lag auto-correlation, no matter the lag value. Such a series is called white noise and it is not predictable.</p>

<p>Let’s plot some generated time series to explore the PCF and PACF charts for various cases.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">white_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plot_acf</span><span class="p">(</span><span class="n">white_noise</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plot_pacf</span><span class="p">(</span><span class="n">white_noise</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="https://alexandrugris.github.io/assets/ts_acf_white_noise.png" alt="ACF White Noise" /></p>

<p><img src="https://alexandrugris.github.io/assets/ts_pacf_white_noise.png" alt="PACF White Noise" /></p>

<p>Let’s plot a perfect AR(1) model, with no noise.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># ar(1) process</span>
<span class="n">ts2</span> <span class="o">=</span> <span class="p">[</span><span class="n">white_noise</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">phi_0</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">phi_1</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">0</span> <span class="c"># 0 = perfectly noiseless, 1 = very noisy</span>

<span class="c"># Expected value of the timeseries (perfect timeseries converges to this value)</span>
<span class="n">miu</span> <span class="o">=</span> <span class="n">phi_0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">phi_1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Expected value: "</span><span class="p">,</span> <span class="n">miu</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">):</span>
    <span class="c"># note that without the error term this goes fast to the mean</span>
    <span class="c"># AR(1)</span>
    <span class="n">ts2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">phi_0</span> <span class="o">+</span> <span class="n">ts2</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">phi_1</span> <span class="o">+</span> <span class="n">k</span> <span class="o">*</span> <span class="n">white_noise</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="n">ts2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ts2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ts2</span><span class="p">)</span>

<span class="n">plot_acf</span><span class="p">(</span><span class="n">ts2</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plot_pacf</span><span class="p">(</span><span class="n">ts2</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p>The time series converges to <code class="highlighter-rouge">miu=phi_0 / (1-phi_1) = 50</code>.</p>

<p><img src="https://alexandrugris.github.io/assets/ts_perfect_ar_1.png" alt="Perfect AR converges to expected value" /></p>

<p><img src="https://alexandrugris.github.io/assets/ts_perfect_ar_1_acf.png" alt="Perfect AR(1) ACF" /></p>

<p><img src="https://alexandrugris.github.io/assets/ts_perfect_ar_1_pacf.png" alt="Perfect AR(1) PACF" /></p>

<p>The same expected value can be observed if we increase the noise:</p>

<p><img src="https://alexandrugris.github.io/assets/ts_ar1_noisy.png" alt="Noisy AR(1)" /></p>

<p>Now, let’s plot an MA (moving average) process:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ts3</span> <span class="o">=</span> <span class="p">[</span><span class="n">white_noise</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">mean</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">phi_1</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">):</span>
    <span class="c"># MA(1) - coef applied to the previous error</span>
    <span class="n">ts3</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean</span> <span class="o">+</span> <span class="n">white_noise</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">theta_1</span> <span class="o">*</span> <span class="n">white_noise</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="n">ts3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ts3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ts3</span><span class="p">)</span>

<span class="n">plot_acf</span><span class="p">(</span><span class="n">ts3</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plot_pacf</span><span class="p">(</span><span class="n">ts3</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="https://alexandrugris.github.io/assets/ts_ma1.png" alt="MA(1)" /></p>

<p><img src="https://alexandrugris.github.io/assets/ts_ma1_acf.png" alt="MA(1) ACF" /></p>

<p><img src="https://alexandrugris.github.io/assets/ts_ma1_pacf.png" alt="MA(1) PACF" /></p>

<p>Unlike an autoregressive process, which has a slowly decaying ACF, the definition of the MA process ensures a sharp cutoff of the ACF for any value greater than q, the order of the MA process. This is because an autoregressive process depends on previous terms, and they incorporate previous impulses to the system, whereas an MA model, incorporating the impulses directly through their value, has a mechanism to stop the impulse propagation from progressing indefinitely. This also means that, forecasting beyond the value lag value of q will only return the mean, since there is no more noise to incorporate.</p>

<p>To summarize, when trying to identify what kind of model we try to fit, we have the following rules:</p>

<ul>
  <li><em>AR(p)</em> - ACF falls off slowly, PACF has sharp drop after lag = p</li>
  <li><em>MA(q)</em> - ACF has a sharp drop after lag = q,  PACF falls off slowly</li>
  <li><em>ARMA(p,q)</em> - No sharp cutoff, neither for ACF nor for PACF</li>
</ul>

<h1 id="fitting-arima-models">Fitting ARIMA Models</h1>

<p>An ARIMA model has 3 parameters:</p>

<ul>
  <li><code class="highlighter-rouge">p</code> : the order of autoregression (the summation of the weighted lags) - <code class="highlighter-rouge">AR</code></li>
  <li><code class="highlighter-rouge">d</code> : the degree of differencing (used to make the dataset stationary if it is not) - <code class="highlighter-rouge">I</code></li>
  <li><code class="highlighter-rouge">q</code> : the order of moving average (the summation of the lags of the forecast errors) - <code class="highlighter-rouge">MA</code></li>
</ul>

<p>Examples (<code class="highlighter-rouge">ARIMA(p, d, q)</code>):</p>

<ul>
  <li><code class="highlighter-rouge">ARIMA (p=1, d=0, q=0) &lt;=&gt; Y(t) = coef + phi_1 * Y(t-1) + error(t)</code> - lag 1 autoregressive model</li>
  <li><code class="highlighter-rouge">ARIMA (p=1, d=0, q=1) &lt;=&gt; Y(t) = coef + phi_1 * Y(t-1) + theta_1 * error(t-1) + error(t)</code> -</li>
  <li><code class="highlighter-rouge">ARIMA (p=0, d=1, q=0) &lt;=&gt; Y(t) = coef + Y(t-1) + error(t)</code> is a random walk. The differencing equation, <code class="highlighter-rouge">Y(t) - Y(t-1) = coef + error(t)</code>, is needed so that the remaining <code class="highlighter-rouge">ARMA</code> model is applied on stationary data. A random walk is not stationary.</li>
  <li><code class="highlighter-rouge">ARIMA(p=0, d=1, q=1)</code> is an exponential smoothing model</li>
</ul>

<p># ARIMA Model Parameter Selection</p>

<p>First step is to check for stationarity using the Augmented Dickey-Fuller test. If the data is not stationary, we need to set the <code class="highlighter-rouge">d</code> parameter.</p>

<p>The second step is to set the <code class="highlighter-rouge">p</code> and <code class="highlighter-rouge">q</code> parameters by inspecting the <code class="highlighter-rouge">ACF</code> and <code class="highlighter-rouge">PACF</code> plots, as described before.</p>

<p>To avoid over-fitting, a rule of thumb is to start the parameter selection with the plot that has the least amount of lags outside of the significance bands and then consider the lowest reasonable amount of lags. The ARIMA model is not necessary unique, as we will see in the following example where we start from a complex timeseries which can be approximated very well with a simpler model.</p>

<p>Let’s generate some data:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">arma_series</span> <span class="o">=</span> <span class="p">[</span><span class="n">white_noise</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">white_noise</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">phi_1</span> <span class="o">=</span> <span class="mf">0.4</span>
<span class="n">phi_2</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">theta_1</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">theta_2</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="c"># AR(2) I(0) MA(2)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">):</span>
    <span class="n">arma_series</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> \
        <span class="n">m</span> <span class="o">+</span> \
        <span class="n">arma_series</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">phi_1</span> <span class="o">+</span> <span class="n">arma_series</span> <span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">phi_2</span> <span class="o">+</span> \
        <span class="n">white_noise</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">theta_1</span> <span class="o">*</span> <span class="n">white_noise</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">theta_2</span> <span class="o">*</span> <span class="n">white_noise</span> <span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">arma_series</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">adf</span> <span class="o">=</span> <span class="n">adfuller</span><span class="p">(</span><span class="n">arma_series</span><span class="p">,</span> <span class="n">autolag</span><span class="o">=</span><span class="s">'AIC'</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">adf</span><span class="p">)</span> <span class="c"># stationary</span>

<span class="n">arma_series</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">arma_series</span><span class="p">)</span>

<span class="c"># fit the model</span>
<span class="n">plot_acf</span><span class="p">(</span><span class="n">arma_series</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plot_pacf</span><span class="p">(</span><span class="n">arma_series</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="https://alexandrugris.github.io/assets/ts_ts.png" alt="Time Series" /></p>

<p><img src="https://alexandrugris.github.io/assets/ts_ts_acf.png" alt="Time Series ACF" /></p>

<p><img src="https://alexandrugris.github.io/assets/ts_ts_pacf.png" alt="Time Series PACF" /></p>

<p>We observe a sharp cutoff in the PACF after lag 1 and slow decay in the ACF. This leads to try to fit an <code class="highlighter-rouge">ARIMA(1, 0, 0)</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">statsmodels.tsa.arima.model</span> <span class="kn">import</span> <span class="n">ARIMA</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">ARIMA</span><span class="p">(</span><span class="n">arma_series</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">arma_series</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">fittedvalues</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"orange"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">arparams</span><span class="p">)</span> <span class="c"># 0.78</span>
</code></pre></div></div>

<p><img src="https://alexandrugris.github.io/assets/ts_ts_fitted.png" alt="Fitted time series (orange)" /></p>

<p>A pretty good approximation of the initial complex model can be obtained with an AR(1) model. Let’s analyse the residuals to see how much information did we capture in our model and if there are autoregressive behaviors we have missed. In our case residuals are normally distributed as seen in the histogram and proven by the Shapiro test and in the ACF and PACF plots we do not see any autoregressive tendencies we might have missed.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">resid</span> <span class="o">=</span> <span class="n">arma_series</span> <span class="o">-</span> <span class="n">results</span><span class="o">.</span><span class="n">fittedvalues</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">resid</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="n">stats</span>
<span class="c"># visual inspection of the residuals</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">resid</span><span class="p">)</span>
<span class="c"># Shapiro test for normality</span>
<span class="n">stats</span><span class="o">.</span><span class="n">shapiro</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">zscore</span><span class="p">(</span><span class="n">resid</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>

<span class="c"># no autocorrelation</span>
<span class="n">plot_acf</span><span class="p">(</span><span class="n">resid</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plot_pacf</span><span class="p">(</span><span class="n">resid</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="https://alexandrugris.github.io/assets/ts_residuals.png" alt="Residuals Histogram" /></p>

<p><img src="https://alexandrugris.github.io/assets/ts_residuals_acf.png" alt="Residuals ACF" /></p>

<p><img src="https://alexandrugris.github.io/assets/ts_residuals_pacf.png" alt="Residuals PACF" /></p>

  </div>

  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">From The Trenches - The Code</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              From The Trenches - The Code
            
            </li>
            
            <li><a href="mailto:alexandru.gris2006@gmail.com">alexandru.gris2006@gmail.com</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/alexandrugris"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">alexandrugris</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/alexandrugris"><span class="icon icon--twitter"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">alexandrugris</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Alexandru Gris - Personal Blog
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
