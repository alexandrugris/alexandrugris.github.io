<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Probability Notes</title>
  <meta name="description" content="A short introduction to probability. A collection of notes I took for myself, published here.">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="https://alexandrugris.github.io/statistics/2018/07/26/probability.html">
  <link rel="alternate" type="application/rss+xml" title="From The Trenches - The Code" href="/feed.xml">
  
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">

    <div class="site-nav"><a class="site-title" href="/">From The Trenches - The Code</a> </div>

    <nav class="site-nav">
      <span class="menu-icon">        
      </span>

      <div class="trigger">

        <a class="page-link" href="https://alexandrugris.github.io">Home</a>

        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
          <a class="page-link" href="/sm/">Social Media</a>
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Probability Notes</h1>
    <p class="post-meta"><time datetime="2018-07-26T14:15:16+03:00" itemprop="datePublished">Jul 26, 2018</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>A short introduction to probability. A collection of notes I took for myself, published here.</p>

<h3 id="counting">Counting</h3>

<p><em>Given 3 locations, A, B, C, and 3 roads from A to B and 2 roads from B to C, how many possible routes are from A to C?</em>  <code class="highlighter-rouge">3 x 2 = 6</code></p>

<p><em>Given a bag with 3 balls, R, G and B. Provided that we take balls out of the bag one by one and don’t put them back (no replacement), how many possible ways of extracting the balls there are?</em>  <code class="highlighter-rouge">3 x 2 x 1 = 6</code>, called permutations.</p>

<p><em>Given a bag with <code class="highlighter-rouge">N</code> balls, provided that we take k balls from the bag without replacement, how many possible ways of extracting the balls are there?</em>  <code class="highlighter-rouge">N x (N-1) x .. x k = N! / (N-k)!</code> and the number is called arrangements.</p>

<p><em>What if I put the balls back?</em>  <code class="highlighter-rouge">N^k</code></p>

<p><em>Given a room with <code class="highlighter-rouge">k</code> people, <code class="highlighter-rouge">k &lt; 365</code>, what is the probability of at least 2 people in the room have the same birthday?</em>  there are <code class="highlighter-rouge">365^k</code> ways of arranging birthdays (sample space). Number of arrangements when each birthday is different is <code class="highlighter-rouge">365 x 364 x .. x k</code> (first one can be born any day of the year, second any day except the day of the first one etc). This leads to a probability of <code class="highlighter-rouge">P = (N! / (N-k)!) / (N^k) = A(365, k) / 365^k</code> of no two people being born in the same day. Thus, the answer is <code class="highlighter-rouge">P = 1 - P</code></p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="nb">reduce</span>

<span class="k">def</span> <span class="nf">arrangements</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="s">""" We will not use this function as it will overflow for large values. Provided just fo example"""</span>
    <span class="k">return</span> <span class="nb">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="n">kk</span> <span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="p">)))</span>

<span class="k">def</span> <span class="nf">at_least_two_people_in_same_day</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="s">""" If we use arrangements function, it will overflow """</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span><span class="p">,</span> <span class="p">((</span><span class="mi">365</span><span class="o">-</span><span class="n">kk</span><span class="p">)</span> <span class="o">/</span> <span class="mi">365</span> <span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="p">)))</span>

<span class="n">at_least_two_people_in_same_day</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">at_least_two_people_in_same_day</span><span class="p">(</span><span class="mi">360</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="p">[</span><span class="n">at_least_two_people_in_same_day</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)])</span>
</code></pre>
</div>

<p>Note: at aroung 60 people in the room, the probability is basically 1 for two people to have the same birthday.</p>

<p><em>The number of subsets of a set</em> is a similar problem to extractions without replacement, but this time the order does not matter. That is, given the example with the bag of <code class="highlighter-rouge">R</code>, <code class="highlighter-rouge">G</code>, <code class="highlighter-rouge">B</code> balls earlier, the <code class="highlighter-rouge">R-G-B</code> and <code class="highlighter-rouge">B-G-R</code> extractions are the same. How many possible ways of extracting the balls are there?</p>
<ul>
  <li>We take the number of picks (arrangements): <code class="highlighter-rouge">A(N, k) = N x (N-1) x ... (N-k) = N! / (N-k)!</code></li>
  <li>We divide this number by the total number of permutations possible in each pick as we count each pick as one:  <code class="highlighter-rouge">A(N, k) / k!</code></li>
  <li>We call this number <em>combinations</em> <code class="highlighter-rouge">C(N, k) = N! / (k! * (N-k)!)</code>, sometimes also called <em>choose k out of N</em>.
Small note: <code class="highlighter-rouge">C(N, k) = C(N, N-k)</code></li>
</ul>

<p><em>Given a set of <code class="highlighter-rouge">N</code> coin tosses, what is the probability of getting exactly <code class="highlighter-rouge">k</code> heads?</em></p>
<ul>
  <li>There are <code class="highlighter-rouge">2^N</code> possible ways of extracting the coins - extraction with replacement.</li>
  <li>There are precisely <code class="highlighter-rouge">C(N, k)</code> ways you can get <code class="highlighter-rouge">k</code> heads in a string of <code class="highlighter-rouge">N</code> tosses</li>
  <li><code class="highlighter-rouge">P = n / sample-space-size = C(N, k) / 2^N</code></li>
</ul>

<p>Obiously, if we want to compute the probability of having k heads or less, we get:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>P = P(0) + P(1) +.. +P(k) = (C(N, 0) + C(N, 1) + ... C(N, k)) / 2^N`
</code></pre>
</div>

<p><em>Given a class of <code class="highlighter-rouge">N</code> boys and <code class="highlighter-rouge">M</code> girls, pick <code class="highlighter-rouge">k</code> children at random, what is the probability of picking precisely <code class="highlighter-rouge">g</code> girls?</em></p>

<div class="highlighter-rouge"><pre class="highlight"><code>P(g girls out of M girls) = C(M, g)
P(k-g boys ot of N boys) = C(N, k-g)
</code></pre>
</div>

<p>The total number of possible picks is <code class="highlighter-rouge">C(M+N, k)</code></p>

<div class="highlighter-rouge"><pre class="highlight"><code>P = (C(M, g) + C(N, k-g)) / C(M+N, k)
</code></pre>
</div>

<p><em>Given a group of <code class="highlighter-rouge">N</code> people, how any ways can people be assigned to <code class="highlighter-rouge">n</code> groups of <code class="highlighter-rouge">k1, k2.., kn</code> people respectively?</em></p>

<div class="highlighter-rouge"><pre class="highlight"><code>G1 = C(N, k1)
G2 = C(N-k1, k2)
...
Gn = C(N - sum(k1, .., kn-1), kn)

Total count: 
T = G1 x G2 x ... x Gn = N! / (k1! x k2! x ... x kn!)
</code></pre>
</div>

<p><em>Given <code class="highlighter-rouge">a</code> a’s, <code class="highlighter-rouge">b</code> b’s, <code class="highlighter-rouge">c</code> c’s, how many ways can these be arranged?</em>
We have <code class="highlighter-rouge">N = a + b + c</code> numbers
<code class="highlighter-rouge">G1 = C(N, a)</code>
<code class="highlighter-rouge">G2 = C(N, b)</code>
<code class="highlighter-rouge">G3 = C(N, c)</code></p>

<p>Total count: <code class="highlighter-rouge">T = G1 x G2 x G3 = (a+b+c)! / (a! x b! x c!) = C(N, a, b, c)</code> - multinomial coefficient.</p>

<h3 id="conditional-probability">Conditional Probability</h3>

<p>By definition, <code class="highlighter-rouge">P(A given B) = P (A | B) = P(A and B) / P(B)</code>, is called conditional probability.</p>

<p>We say that two events are independent if <em>any</em> of the following holds:</p>

<ul>
  <li><code class="highlighter-rouge">P(A | B) = P(A)</code></li>
  <li><code class="highlighter-rouge">P(B | A) = P(B)</code></li>
  <li><code class="highlighter-rouge">P(A and B) = P(A) x P(B)</code></li>
</ul>

<p>If <em>none</em> of the above holds true, we say the events are dependent.</p>

<p><em>Given 3 events and a 6-sided die, A: odd number rolled, B: even number rolled, C: {1, 2}, what is the relationship of dependence / independence between these events?</em></p>

<ul>
  <li><code class="highlighter-rouge">P(A | B) = P(odd number rolled given even number roll) = 0</code>. <code class="highlighter-rouge">P(A and B) = 0</code> which is different from <code class="highlighter-rouge">P(A) * P(B)</code>, thus the events are <em>dependent</em>.</li>
  <li><code class="highlighter-rouge">P(A | C) = 1/2 = P(A)</code>, thus the two events are <em>independent</em></li>
</ul>

<p>Obviously:
<code class="highlighter-rouge">P(A and B) = P(B) x P(A given B) = P(A) x P(B given A)</code></p>

<p><em>Law of total probability</em> says that, given a probability space <code class="highlighter-rouge">S</code> and a partition <code class="highlighter-rouge">S1,..., Sn</code> with <code class="highlighter-rouge">S = S1 U S2 U ... U Sn</code>, <code class="highlighter-rouge">P(A) = sum(P(Bk) * P(A | Bk), for k from 1 to n)</code>. In other words, probability of an event A is equal to the sum of probabilities of us being in a partition multiplied by the probability of A given we are in that partition.</p>

<p><em>Bayes theorem:</em> given a sample space <code class="highlighter-rouge">S</code> and events <code class="highlighter-rouge">B1, ... ,Bk</code> forming a partition over <code class="highlighter-rouge">S</code>, and a random event A,</p>

<div class="highlighter-rouge"><pre class="highlight"><code>P(Bi | A) = P(Bi) * P(A | Bi) / sum(P(Bj) * P(A | Bj), j = 1..k)
</code></pre>
</div>

<p>Let’s apply this theorem to the well know problem of tests and probability of disease. Given the following:</p>

<ul>
  <li><code class="highlighter-rouge">P(positive | have the disease) = 0.9</code></li>
  <li><code class="highlighter-rouge">P(positive | you don't have the disease) = 0.1</code></li>
  <li><code class="highlighter-rouge">P(you have the disease) = 1 in 10000</code></li>
</ul>

<p>If you test positive, what i the probability that you have the disease?</p>

<ul>
  <li>The sample space <code class="highlighter-rouge">S = B1 + B2</code>, you have the disease or you don’t have the disease, the partition fully covers the space.</li>
  <li>Event A = you tested positive</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>P(B1 = you have the disease) = P(B1) * P(A | B1) / sum (...) 
P(B1) = (1/10000 * 0.9) / (P(B1) * P(A | B1)) + P(B2) * P(A | B2))
P(B1) = (0.9 / 10000) / (1/10000 * 0.9 + 9999/10000 * 0.1)
p(B1) = approx 1 in 1000
</code></pre>
</div>

<h3 id="random-variables-and-distributions">Random variables and distributions</h3>

<p><em>Probability function</em> is defined as <code class="highlighter-rouge">f(x) = P(X = x)</code>, where X is a random variable. E.g. : <code class="highlighter-rouge">f(x) = { 1/6 for x in 1..6, 0 otherwise }</code>. This is also <em>called probability mass function (pmf)</em>.</p>

<p><em>Uniform distribution</em> has `pmf(X = x, a &lt;= x &lt;= b, a, b natural numbers) = { 1/(b-a +1) for x = a…b, 0 otherwise }</p>

<p><em>Binomial distribution</em> deals with items that can be in in two distinctive states, each with probability <code class="highlighter-rouge">p</code> or <code class="highlighter-rouge">1-p</code>. A single experiment is called a <em>Bernoulli trial</em>. For instance, given a string of <code class="highlighter-rouge">N</code> coin tosses, with <code class="highlighter-rouge">p</code> the probability of turning head, the probability of getting exactly <code class="highlighter-rouge">k</code> heads and thus <code class="highlighter-rouge">N-k</code> tails is <code class="highlighter-rouge">C(N, k) x p^k x (1-p)^(N-k)</code>.</p>

<ul>
  <li>Probability of a single string of events is <code class="highlighter-rouge">p^k x (1-p)^(N-k)</code></li>
  <li>There are <code class="highlighter-rouge">A(N, k)</code> arrangements of such strings, each representing one of the <code class="highlighter-rouge">k!</code> possible permutations, which is precisely the definition for <code class="highlighter-rouge">C(N, k)</code>.</li>
</ul>

<p><em>Geometric distribution</em> still refers to a string of Bernoulli trials, just like the binomial distribution, but, unlike the binomial distribution which answers the question <em>what is the probability of an event to occur X times</em>, the geometric distribution answers the question <em>what is the probability that the first success occurs after the X trials</em>.</p>

<p>The events are:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>E1 = Success (x=1, p(E1) = p)
E2 = Failure, Success (x=2, P(E2) = (1-p) * p)
E3 = Failure, Failure, Success (x=3, P(E3) = (1-p) * (1-p) * p)`
...

Thus `pmf(x) = (1-p)^(x-1) * p`
</code></pre>
</div>

<p><em>An example:</em></p>

<p>Suppose we have an airplane which has a probability to crash on each flight equals to <code class="highlighter-rouge">p</code>, with this probability independent on the number of flights previously performend. Thus, on the first flight probability to crash is <code class="highlighter-rouge">p</code>, on the second flight probability to crash if <code class="highlighter-rouge">(1-p) * p</code> and so on. The question is, what is the probability the plane will at least N flights? Answer: <code class="highlighter-rouge">P(N flights) = 1 - SUM( p(x), x = 1...N )</code>.</p>

<ol>
  <li><em>Hypergeometric distribution</em> still deals with items that can be in two possible states, but unlike the binomial distribution, extractions are without replacement. For instance, assuming a bag of balls each of two colors, red or blue, we would use the binomial distribution to compute the probability of N red balls extracted if the red ball is put back in the bag and the hypergeometric distribution if the ball is not.</li>
</ol>

<p><em>Assuming we have a bag with <code class="highlighter-rouge">N</code> balls, <code class="highlighter-rouge">R</code> red and <code class="highlighter-rouge">B</code> blue, with <code class="highlighter-rouge">R+B=N</code> and we extract balls from the bag without putting them back, after extracting <code class="highlighter-rouge">n</code> balls from the bag, what is the probability of having extracted <code class="highlighter-rouge">k</code> red balls?</em></p>

<p><code class="highlighter-rouge">pmf(x) = C(R, x) * C(N-R, n-x) / C(N, n)</code> where:</p>

<ul>
  <li><code class="highlighter-rouge">R</code> is the number of success states (in our case the number of red balls)</li>
  <li><code class="highlighter-rouge">n</code> is the number of draws</li>
  <li><code class="highlighter-rouge">x</code> is the number of observed successes, in this case we would replace it with <code class="highlighter-rouge">k</code></li>
  <li><code class="highlighter-rouge">N</code> is the population size</li>
</ul>

<p><em>Assuming a a box with <code class="highlighter-rouge">N</code> newly built CPUs. We know that 1 in <code class="highlighter-rouge">X</code> is defective. We are invited to pick <code class="highlighter-rouge">K</code>. What is the probability of none being defective?</em></p>

<p><code class="highlighter-rouge">P(none defective) = C(N - N/X, K) * C(N/X, 0) / C(N, K)</code> with <code class="highlighter-rouge">R = N - N/X</code>, <code class="highlighter-rouge">x = K</code> and <code class="highlighter-rouge">n = K</code> if we are to use the terminology from the formula above.</p>

<p><em>Continuous distributions</em> are those distributions for which <code class="highlighter-rouge">P(X = x) = 0</code> thus it would only make sense to talk about <code class="highlighter-rouge">P(a &lt;= X &lt;= b)</code>. For continuous distributions we define the <em>cummulative distribution function</em>, <code class="highlighter-rouge">cdf</code>, as <code class="highlighter-rouge">cdf(x) = P(X &lt;= x)</code> and <em>probability density function</em>, <code class="highlighter-rouge">pdf</code>, as <code class="highlighter-rouge">pdf(x) = cdf(x)dx / dx = cdf'(x)</code> with <code class="highlighter-rouge">integral(-infinty, infinity)(pdf(x)) = 1</code>. Looping back to computing the <code class="highlighter-rouge">P(a &lt;= X &lt;= b )</code>, <code class="highlighter-rouge">P(a &lt;= x &lt;= b) = integral(a, b)(pdf(x))</code>.</p>

<p><em>Standard normal distribution</em> has the expected value <code class="highlighter-rouge">miu = 0</code> and standard deviation <code class="highlighter-rouge">sigma = 1</code>. One can transform any normal distribution of a given <code class="highlighter-rouge">miu</code> and <code class="highlighter-rouge">sigma</code> to the standard by applying <code class="highlighter-rouge">z=(x-miu)/sigma</code> as in the following example: assuming that the scores for an exam are centered around 75%, with a standard deviation of 10%, what fraction of the scores lie between 80% and 90%?</p>

<div class="highlighter-rouge"><pre class="highlight"><code>z1 = (80-75)/10 = 0.5
z2 = (90-75)/10 = 1.5
answer = cdf_normal(1.5) - cdf_normal(0.5)
</code></pre>
</div>

<p><em>Gamma distribution</em>, link <a href="https://en.wikipedia.org/wiki/Gamma_distribution">here</a>, is a two-parameter family of continuous probability distributions. The exponential distribution, Erlang distribution, and chi-squared distribution are special cases of the gamma distribution.</p>

<p><em>Beta distribution</em>, link <a href="https://en.wikipedia.org/wiki/Beta_distribution">here</a>, used in Bayesian inference to solve problems which follow a pattern similar to the following: “given our belief of the world at a certain point of time, if new evidence becomes available, how do these affect our beliefs?”. A good example is spam filtering.</p>

<h3 id="expectation">Expectation</h3>

<p>Expected value is defined as <code class="highlighter-rouge">E[V] = sum(p1*v1 + p2*v2+ ... pn*vn)</code> where <code class="highlighter-rouge">pi</code> is the probability for <code class="highlighter-rouge">vi</code> to occur. It is called also mean or average. For example, the expectation for a binomial distribution with the probability <code class="highlighter-rouge">p</code> for <code class="highlighter-rouge">1</code>  and <code class="highlighter-rouge">1-p</code> for <code class="highlighter-rouge">0</code> is <code class="highlighter-rouge">E[X] = (1-p)*0 + 1*p = p</code>.</p>

<p>For continuous distributions, the <code class="highlighter-rouge">E[X] = integral(-inf, +inf, dx)(x * pdf(x))</code>.</p>

<p>Considering a part that has the fail probability density function <code class="highlighter-rouge">pdf = 2*x, for 0&lt;=x&lt;=1 and 0 otherwise</code>, the expected time to fail is <code class="highlighter-rouge">E[X] = integral(0, 1, dx)(2 * x^2) = 2/3 * x^3 for x = 1 - 2/3 * x^3 for x = 0 = 2/3</code>. Note: <code class="highlighter-rouge">2*x</code> is a valid pdf, with <code class="highlighter-rouge">cdf=x^2</code>, monotonically increasing, and <code class="highlighter-rouge">integral(0,1)(pdf) = cdf(1) - cdf(0) = 1</code>. It can be explained as the probability of defect as it reaches the end-of-life increases squarely.</p>

<p><a href="https://en.wikipedia.org/wiki/Law_of_the_unconscious_statistician">Law of the unconscious statistician</a> helps calculate the expected value of a function g(X) of a random variable X when one knows the probability distribution of X but one does not explicitly know the distribution of g(X).</p>

<p>For the discrete case, the formula is:</p>

<p><code class="highlighter-rouge">E[g[X]] = sum(g(x) * f_X(x))</code></p>

<p>for the continuous case:</p>

<p><code class="highlighter-rouge">E[g[X]] = integral(-inf, inf, dx)(g(x) * f_X(x))</code></p>

<p><em>Variance</em> is a measure of how spread out the values are spread around the mean. We define the variance for a random variable as <code class="highlighter-rouge">V[X] = E[(x - mean)^2]</code>. We define also the standard deviation as <code class="highlighter-rouge">sigma[X] = sqrt(V[X])</code>.</p>

<p>For a binomial distribution, with <code class="highlighter-rouge">p=0.5</code>:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>mean = E[X] = 0 * 0.5 + 1 * 0.5 = 0.5
V[X] = E[(X-mean)^2] = 0.5 * (0-0.5)^2 + 0.5 * (1-0.5)^2 = 0.5 * 0.25 + 0.5 * 0.25 = 0.25
sigma = sqrt(0.25) = 0.5`
</code></pre>
</div>

<p>Another way to computing the variance is:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>V[X] = E[(X-mean)^2] = E[X^2 - 2*X*mean + mean^2] = E[X^2] - 2 * E[X] * mean + mean^2 = E[X^2] - mean^2
</code></pre>
</div>

<p>A nice property of variance is that <code class="highlighter-rouge">V[a1X1 + a2X2 + ... +b] = a1^2 * V[X1] + ... + an^2 * V[Xn]</code>.</p>

<p><em>The joint probability mass function for two random variables X and Y</em> is defined as <code class="highlighter-rouge">P_XY(x,y) = P(X=x, Y=y)</code> with <code class="highlighter-rouge">sum(P_XY(x, y)) = 1</code></p>

<p>To compute the measure of two variables varying together, we introduce the notion of <em>covariance</em>, which standardizes to <em>correlation</em> (covariance is dependend of the values of the two variables).</p>

<p><code class="highlighter-rouge">cov(X, Y) = sigma(x, y) = E[(X-mean(X)) * (Y - mean(Y))]</code></p>

<p>and</p>

<p><code class="highlighter-rouge">corr(X, Y) = cov(X, X) / (stddev(X) * stddev(Y))</code></p>

<p>Correlation is constrained to the interval <code class="highlighter-rouge">(-1, 1)</code>, with <code class="highlighter-rouge">0</code> meaning that <code class="highlighter-rouge">X</code> and <code class="highlighter-rouge">Y</code> are totally uncorrelated. A value over <code class="highlighter-rouge">0.6</code> means strongly correlated, <code class="highlighter-rouge">0.2</code> weakly correlated or almost uncorrelated. One point to note is that correlation only measures linear relationships. Thus a relationship like <code class="highlighter-rouge">(X, X^2)</code> would score very low on the correlation spectrum.</p>

<h3 id="other-interesting-distributions">Other interesting distributions</h3>

<p><em>Poisson distribution</em> models the number of occurences of an event within a given period of time. E.g. goals per match.</p>

<p><em>Lognormal distribution</em> has very interesting applications, described <a href="https://en.wikipedia.org/wiki/Log-normal_distribution#Occurrence_and_applications">here</a>. For instance, In reliability analysis, the lognormal distribution is often used to model times to repair a maintainable system.
The lognormal distribution is a distribution of a random variable <code class="highlighter-rouge">X</code> whose <code class="highlighter-rouge">log(X)</code> is normally distributed.</p>


  </div>

  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">From The Trenches - The Code</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              From The Trenches - The Code
            
            </li>
            
            <li><a href="mailto:alexandru.gris2006@gmail.com">alexandru.gris2006@gmail.com</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/alexandrugris"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">alexandrugris</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/alexandrugris"><span class="icon icon--twitter"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">alexandrugris</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Alexandru Gris - Personal Blog
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
