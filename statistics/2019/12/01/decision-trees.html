<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Decision Trees</title>
  <meta name="description" content="A short introduction to decision trees.">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="https://alexandrugris.github.io/statistics/2019/12/01/decision-trees.html">
  <link rel="alternate" type="application/rss+xml" title="From The Trenches - The Code" href="/feed.xml">
  
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">

    <div class="site-nav"><a class="site-title" href="/">From The Trenches - The Code</a> </div>

    <nav class="site-nav">
      <span class="menu-icon">        
      </span>

      <div class="trigger">

        <a class="page-link" href="https://alexandrugris.github.io">Home</a>

        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
          <a class="page-link" href="/sm/">Social Media</a>
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Decision Trees</h1>
    <p class="post-meta"><time datetime="2019-12-01T13:15:16+02:00" itemprop="datePublished">Dec 1, 2019</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>A short introduction to decision trees.</p>

<h3 id="what-are-decision-trees">What are decision trees</h3>

<p>Decision trees are a supervised machine learning technique used for classification and regression problems. Since the launch of XGBoost, it has been the preferred way of tackling problems at machine learning competitions and not only because of easy setup, learning speed, straightforward tuning parameters, easy to reason about results and, above all, very good results. Arguably, with current implementations, decision trees outperform most of the other machine learning techniques.</p>

<p>As with every other supervised learning techniques, the input to the algorithm in its learning phase is a set of predictors, <code class="highlighter-rouge">Xij</code>, and a set of predicted variables <code class="highlighter-rouge">Yj</code>, with <code class="highlighter-rouge">i</code> between <code class="highlighter-rouge">0</code> and <code class="highlighter-rouge">K</code>, the features, and <code class="highlighter-rouge">j</code> between <code class="highlighter-rouge">0</code> and <code class="highlighter-rouge">N</code>, the number of points in the training set. If the problem is one of classification the <code class="highlighter-rouge">Yj</code> labels, with <code class="highlighter-rouge">Yj</code> belonging to a finite set of labels, <code class="highlighter-rouge">L</code>, with <code class="highlighter-rouge">size(L) &lt;&lt; N</code>.  If the problem is a regression, then <code class="highlighter-rouge">Yj</code> are  numeric values. The output is an decision tree which, for a new input vector, <code class="highlighter-rouge">X'</code> will predict its class (or the regressed value), <code class="highlighter-rouge">Y'</code>. If the problem is one of classification, the label predicted will be the label obtained by the majority vote from the points contained in one of its leafs. If the problem is one of regression, the value predicted will be the average values <code class="highlighter-rouge">Yj</code> of the points contained in the un-split set at one of its leafs.</p>

<h3 id="principles">Principles</h3>

<p>A decision tree is, as the name implies, a tree. Since in the large majority of the cases this tree is binary, we will consider only the binary case in this post.</p>

<p>When parsing the tree, at every node a decision is taken on whether to go right and or left. Each leaf represents the decision to which class that particular path belongs to. In the case of regression trees, it represents the predicted value for the specified set of parameters.</p>

<p>The algorithm works by splitting the nodes based on the value of one of its predictor variables. The algorithm stops usually after some conditions, like the depth of the tree, or the number of leafs, or the number of nodes in a leaf has been been reached, or when all the elements in the leaf belong to a single class. Obviously, the decision trees are very prone either to overfitting by splitting too much, or to underfitting, by taking the decision to stop splitting too early.</p>

<p>These model parameters, which influence when to stop splitting, are tackled by hyperparameter tuning methods, which train trees with various parameters and then pick the most successful ones.</p>

<p>The bias to given by the training set selection or feature choices are tackled by ensemble methods, like random forest or gradient boosted trees, which build several trees based on the input data to query from and then use voting to select the most accurate results.</p>

<h3 id="building-the-tree">Building the tree</h3>

<p>Building the decision tree is a recursive process. At each step a feature is selected and a value based on which to do the split. The selection is made such that the highest information gain is attained, that is, the set is best split across its categories, meaning each group as as homogenous as possible.</p>

<h3 id="todo-analyze-with-decision-trees-the-data-from-telco---the-one-with-telco-from----telcocsv-in-data-folder">TODO: analyze with decision trees the data from telco -&gt; the one with telco from  - telco.csv in data folder</h3>

  </div>

  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">From The Trenches - The Code</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              From The Trenches - The Code
            
            </li>
            
            <li><a href="mailto:alexandru.gris2006@gmail.com">alexandru.gris2006@gmail.com</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/alexandrugris"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">alexandrugris</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/alexandrugris"><span class="icon icon--twitter"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">alexandrugris</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Alexandru Gris - Personal Blog
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
